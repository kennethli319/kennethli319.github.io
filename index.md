---
layout: default
---

[LinkedIn](https://www.linkedin.com/in/wang-yau-li/)

# About

I am deeply passionate about leveraging my expertise in Linguistics and Machine Learning to revolutionize Human-Computer Interaction. Aspiring to contribute significantly to the AI industry, I focus on automatic speech recognition (ASR), natural language understanding (NLU), and neurotechnology. My commitment lies in enhancing user experiences by developing innovative solutions in these cutting-edge fields.

# Experience

Dialpad - Speech Recognition Engineer - Feb 2020 - Aug 2023

- Drove research and development to develop better models for speech recognition with Kaldi, NeMo, and K2
- Enhanced transcript accuracy through data augmentation and model optimization
- Improved keyword adaptation that suits customers' unique vocabulary with contextual biasing
- Maintained routine model building and monitoring of model performance
- Collaborated closely with the natural language processing team to optimize input quality and ensure superior outcomes

# Education

The University of Edinburgh - Master's degree, Speech & Language Processing - 2018 - 2019

Thesis: Robust Word Recognition and Alignment of Child Speech Therapy Sessions using Audio and Ultrasound Imaging (with Kaldi and PyTorch)

City University of Hong Kong - Bachelor of Arts - BA, Linguistics and Language Applications - 2014 - 2018

Thesis: A Comparative Study of Interlingual vs. Neural Approach to Machine Translation of Numerical Expressions (with Java and Tensorflow)

Conference: AI and Linguistics Conference - East China Normal University - Oct. 26-28 2018 - "Can linguistics help neural machine translation? - Evidence from a case study of interlingual vs neural machine translation of numerical expressions" - Dr. Chunyu Kit (CityU) and Kenneth Wang Yau Li (Edinburgh)

# Projects

## ASR
## NLP
## TTS
## EEG

# Research

- [N-gram Boosting: Improving Contextual Biasing with Normalized N-gram Targets](https://arxiv.org/abs/2308.02092)
- [Avengers, Ensemble! Benefits of ensembling in grapheme-to-phoneme prediction](https://aclanthology.org/2021.sigmorphon-1.16v2.pdf)

