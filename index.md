---
layout: default
---

[LinkedIn](https://www.linkedin.com/in/wang-yau-li/)

# About

I am deeply passionate about leveraging my expertise in Linguistics and Machine Learning to revolutionize Human-Computer Interaction. Aspiring to contribute significantly to the AI industry, I focus on automatic speech recognition (ASR), natural language understanding (NLU), and neurotechnology. My commitment lies in enhancing user experiences by developing innovative solutions in these cutting-edge fields.

---

# Experience

#### Speech Recognition Engineer - Dialpad - Feb 2020 - Aug 2023

- Drove research and development to develop better models for speech recognition with Kaldi, NeMo, and K2
- Enhanced transcript accuracy through data augmentation and model optimization
- Improved keyword adaptation that suits customers' unique vocabulary with contextual biasing
- Maintained routine model building and monitoring of model performance
- Collaborated closely with the natural language processing team to optimize input quality and ensure superior outcomes

#### Research Assistant - City University of Hong Kong - Jul 2018 - Sep 2018

- Research project: "Develop a large scale Chinese reading corpus for machine learning of unconscious word segmentation from eye movements"
- Analysed Chinese word segmentation tasks with eye tracking data

---

# Education

#### Master's degree, Speech & Language Processing - The University of Edinburgh - 2018 - 2019

Thesis: Robust Word Recognition and Alignment of Child Speech Therapy Sessions using Audio and Ultrasound Imaging (with Kaldi and PyTorch)

#### City University of Hong Kong - Bachelor of Arts - BA, Linguistics and Language Applications - 2014 - 2018

Thesis: A Comparative Study of Interlingual vs. Neural Approach to Machine Translation of Numerical Expressions (with Java and Tensorflow)

Conference: AI and Linguistics Conference - East China Normal University - Oct. 26-28 2018 - "Can linguistics help neural machine translation? - Evidence from a case study of interlingual vs neural machine translation of numerical expressions" - Dr. Chunyu Kit (CityU) and Kenneth Wang Yau Li (Edinburgh)

---

# Projects

## ASR
#### Data augmentation with GPT-2 and out-of-domain data

Finetune GPT-2 on in-house data and generate augmented data for LM training. 
Explore data augmentation with public out-of-domain data for LM training

#### Lattice rescoring with LLM

Rescore ASR nbest lattice with various LLM, improving offline performance by 3% relative

#### Keyword contextual biasing


#### Whisper

## NLP

#### Grammatical Error Correction with Gector

Build grammarticall error correction system based on [Gector](https://github.com/grammarly/gector) and optimize model with in-domain-data and model architecture.

#### Model quantization



## TTS
#### Concatination

## EEG
##### EEG Foundation model with EEG-Conformer and GPT
#### EEG Foundation model with wav2vec2

---

# Research

- [N-gram Boosting: Improving Contextual Biasing with Normalized N-gram Targets](https://arxiv.org/abs/2308.02092)
- [Avengers, Ensemble! Benefits of ensembling in grapheme-to-phoneme prediction](https://aclanthology.org/2021.sigmorphon-1.16v2.pdf)

